---
title: "HUGEN 2072 Project 2"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

# Instructions

Below is a tutorial consisting of a mostly-completed QC pipeline and some prompts.

Project 1 has three components:

-   **Scripting/coding**: read through this file and complete the pipeline by contributing your code *where indicated*.

-   **Narrative**: knit the completed .Rmd to a code-integrated HTML report of your QC process and decisions.

    -   Your report must answer all the questions and perform all the tasks indicated in the instructions/prompts given for each step.

    -   You must submit a successfully-knitted HTML file and the `.Rmd` in order to earn a passing grade for this project.

    -   Set up your report to flow like an actual document you might show your supervisor to summarize the QC project, emphasizing what was done at each step rather than the code used to do it (e.g., how many samples/SNPs were filtered out at a given step?)

    -   **Submit your .Rmd and HTML to Canvas**

-   **Presentation**: you will make a 10 min (maximum) recording of yourself with Panopto in which you summarize this QC pipeline. Instructions will given on Canvas.

In each Part of this project you will implement one of the main steps of cleaning genotyping array data in a small dataset (note that we left a few steps out). You'll be shown how to use functions from the `{GWASTools}` package, and you'll supply a little of your own code to complete the pipeline that's been provided. At each step, you may be asked to create a filter for the data, to address errors/discrepancies, etc. Then for each step you'll make a short report (a few sentences and figures) explaining what you did.

Note that "sample" and "scan" are used interchangeably throughout this assignment, but that these are NOT synonymous with subject/participant/individual/etc. In this assignment, "SNP" and "probe" are used interchangeably, but in other contexts you should always remember the distinction.

**Since the pipeline below is incomplete, some of the R code chunks are set to `eval=FALSE` so that knitting to HTML will succeed. You will need to change them to `eval=TRUE` as you progress so that your knitted document shows the results of running each chunk.**

**It is expected that you will copy this file somewhere to your directory on the CRC cluster so that you can use the RStudio Server, where all the packages you need have been installed already.**

## Part 0 - Setup and Introduction to Annotation Data Frames

First, load the packages we'll be using.

```{r load_packages, message=F, eval=TRUE}

# Load the required packages for the project (Install them if necessary)

library("GWASTools", quietly = TRUE)
library("GWASdata", quietly = TRUE)
library("SNPRelate", quietly = TRUE)

# Close any open GDS files before proceeding (think of this as starting off with
# a 'blank slate')

showfile.gds(closeall = T, verbose = T)

```

The array data (genotypes, intensities, and BAF/LRR information) for this project are contained in several GDS files; accompanying SNP and scan annotation are also provided as an `.RData` file.

The probe/SNP annotation is stored in an object called a scan annotation data frame, and the sample-level annotation is stored in a scan annotation data frame. Each of these objects is similar to an ordinary data frame. More precisely, a data frame is embedded within each. There is also accompanying metadata. To access the data and metadata, the `{GWASTools}` package provides several functions. Three basic functions you should familiarize yourself with are `getAnnotation()`/`pData()` (extracts a standard data frame containing the annotation), `getMetadata()`/`varMetadata()` (extracts a data frame of variable descriptions), and `getVariableNames()`/`varLabels()` (extracts a vector of just the variable names). You can also view a variable in one of these objects by using `$`, as you would for an ordinary data frame. You can also add new variables, but you need to be careful to update the metadata as well. Since we will be adding new variables in the process of cleaning our data, the following chunk of code shows you how to do this. Then you will practice looking at the annotation, and your task is to answer some questions about this data set.

First, load the annotation data (`annotation_data.RData`) that was provided with this project. **You need to supply the path to this file.**

```{r load_annotation, eval=TRUE}

# Load the probe (SNP) and sample annotation data frames, which have been saved
# in an .RData file

path_to_annotation_data <-
  "/ix1/hugen2072-2026s/p1/annotation_data.RData"
load(path_to_annotation_data)

# List the loaded objects

ls()

```

Here's a toy example showing you how to work with annotation data frames. **Read this carefully, since you'll need to do this throughout the assignment.**

```{r annotation_data_frame_example, eval=TRUE}

### How to add a new variable to an annotation data frame ###

#   Make a new copy of the SNP annotation (just for this example)

snp_annodf_temp <- snpAnnot

#   Notice that printing the object isn't that helpful

snp_annodf_temp

#   So extract the annotation itself (this is the 'normal' data frame embedded
#   in the SNP annotation data frame object). Now you can see the SNP-level
#   annotation

snp_data_temp <- getAnnotation(snp_annodf_temp)
head(snp_data_temp)

#   Add a new column to the annotation (an integer dummy variable)

snp_data_temp$dummy <- 1:nrow(snp_data_temp)

#   Now update the scan annotation object itself by replacing the what was in
#   the annotation "slot"

pData(snp_annodf_temp) <- snp_data_temp

#   You can see that the new column has been added

head(pData(snp_annodf_temp))

#   Extract the metadata so that it can be updated

meta_temp <- getMetadata(snp_annodf_temp)
meta_temp

#   Add a new row titled "dummy" with an appropriate labelDescription (note that
#   the metadata is a data frame with named rows but one column)

meta_temp["dummy", "labelDescription"] <- "This is a dummy variable"

#   Finally, replace the old metadata with the new metadata

varMetadata(snp_annodf_temp) <- meta_temp

#   Look at the data and metadata to make sure there the dummy variable has been
#   added

head(getAnnotation(snp_annodf_temp))
getMetadata(snp_annodf_temp)

#   Remove the temp files

rm(snp_annodf_temp, snp_data_temp, meta_temp)

```

Now we use `GdsGenotypeReader()` and `GdsIntensityReader()` to open the gds files that contain the array data. Then use `GenotypeData()` and `IntensityData()` to combine them with the SNP and sample annotation, since the functions we'll be using later require this information to be "packaged" together.

```{r load_array_data, eval=TRUE}

#   Get the genotypes from a gds file

genofile <-
  system.file("extdata", "illumina_geno.gds", package = "GWASdata")
gds_geno <- GdsGenotypeReader(genofile)

#   Combine the genotypes with the sample and SNP annotation

genoData <-
  GenotypeData(gds_geno, snpAnnot = snpAnnot, scanAnnot = scanAnnot)
genoData

#   Get the intensity data from a gds file

qxyfile <-
  system.file("extdata", "illumina_qxy.gds", package = "GWASdata")
gds_qxy <- GdsIntensityReader(qxyfile)

#   Combine with the sample and SNP annotation

qxyData <-
  IntensityData(gds_qxy, snpAnnot = snpAnnot, scanAnnot = scanAnnot)
qxyData

#   Get the BAF/LRR data from a gds file

blfile <-
  system.file("extdata", "illumina_bl.gds", package = "GWASdata")
gds <- GdsIntensityReader(blfile)

#   Combine the BAF/LRR data with the sample and SNP annotation

blData <-
  IntensityData(gds, snpAnnot = snpAnnot, scanAnnot = scanAnnot)
blData

```

## Part 0 - Report

Using the functions introduced above to help you, briefly describe the dataset in a few sentences. Answer the following questions. Whatever code you use to help answer these questions can go in the empty chunk that follows.

-   What is the difference between the scanID and subjectID variables? Why are they both provided?

-   How many families are represented, and how many samples are from each family?

-   How many samples are of each sex?

-   How many samples are from each population group?

-   How many samples are there? How many people did they come from?

-   How many SNPs are there?

-   Which chromosomes are represented? How many SNPs are on each?

```{r part0_report}
library(tidyverse)

# Your code goes here
snp <- pData(snpAnnot)
scan <- pData(scanAnnot)
head(snp)
head(scan)

# How many families are represented, and how many samples are from each family?
print('families')
length(unique(scan$family))
scan %>%
  count(family)

# How many samples are of each sex?
scan %>%
  filter(sex == 'M') %>%
  count() # 42
scan %>%
  filter(sex == 'F') %>%
  count() # 35

# How many samples are from each population group?
print('race')
table(scan$race)

# How many samples are there? How many people did they come from?
print('subjects')
length(unique(scan$subjectID))

# how many snps
print('snps')
length(unique(snp$snpID))

# which chromosomes
print('chromosomes')
table(snp$chromosome)
snp %>%
  count(chromosome)
```

## Part 1 - Missing Call Rate for Samples and SNPs

The basic `{GWASTools}` functions for missingness are `missingGenotypeBySnpSex()` and `missingGenotypeByScanChrom()`. `missingGenotypeBySnpSex()` returns a list of three objects: `missing.counts`, `scans.per.sex`, and `missing.fraction`. Read the help file for this function so that you understand what information is contained in these and how the Y chromosome is treated by sex (where sex is as defined in the scan annotation). Similarly, `missingGenotypeByScanChrom()` returns `missing.counts`, `snps.per.chr`, and `missing.fraction`.

There are four basic missingness calculations to be done, in the following order.

1.  Calculate `missing.n1` = fraction of genotype calls missing over all samples (except that annotated ‘female’ individuals are excluded for Y chr SNPs)

2.  Calculate `missing.e1` = missing call rate per sample over all SNPs (excluding SNPs with all calls missing)

3.  Calculate `missing.n2` = call rate per SNP over all samples whose `missing.e1` is less than `0.05`

4.  Calculate `missing.e2` = missing call rate per sample over all SNPs with `missing.n2` values less than `0.05`

We'll want to store the missingness information in the annotation data frames as we proceed.

Here's how to calculate and store `missing.n1`.

```{r missing.n1, eval=TRUE}

### Using missingGenotypeBySnpSex to calculate missing.n1 ###

#   First look at some of the results

miss <- missingGenotypeBySnpSex(genoData)
names(miss)
head(miss$missing.counts)
miss$scans.per.sex
head(miss$missing.fraction)

#   We should make sure the snpIDs are in the same order in the annotation and
#   in the missingness report (miss$missing.fraction); they are

allequal(snpAnnot$snpID, as.numeric(names(miss$missing.fraction)))

#   Then go ahead and add missing.n1 as a new annotation data column, and update
#   the metadata

snpAnnot$missing.n1 <- miss$missing.fraction
varMetadata(snpAnnot)["missing.n1", "labelDescription"] <-
  paste(
    "fraction of genotype calls missing over all samples, except that females are excluded for Y chr SNPs"
  )

### Explore the missing call rate per probes a little more

#   Look at the distribution of missingness for all the probes

hist(
  snpAnnot$missing.n1,
  ylim = c(0, 100),
  xlab = "SNP missing call rate",
  main = "Missing Call Rate for All Probes"
)

#   How many SNPs are missing a genotype for every single sample? Apparently
#   there are 151 such SNPs

sum(snpAnnot$missing.n1 == 1)

#   Store a vector containing the snpIDs of all the SNPs with missingness of
#   100%

snpexcl <- snpAnnot$snpID[snpAnnot$missing.n1 == 1]

```

Now we calculate and store `missing.e1`. The steps are described in the comments below.

```{r missing.e1, eval=TRUE}

### Using missingGenotypeByScanChrom to calculate missing.e1

#   Apply missingGenotypeByScanChrom to genoData, using the snp.exclude option
#   to exclude these SNPs (why does it make sense to exclude those SNPs?)

miss <- missingGenotypeByScanChrom(genoData, snp.exclude = snpexcl)

#   Make sure the order of the scanIDs in the output from
#   missingGenotypeByScanChrom is the same as the order of the scanIDs in the
#   annotation data frame

allequal(names(miss$missing.fraction), scanAnnot$scanID)

#   Make a new column in scanAnnot called missing.e1 and store the per-scan
#   missingness from missingGenotypeByScanChrom there

scanAnnot$missing.e1 <- miss$missing.fraction

#   Update the scanAnnot metadata

varMetadata(scanAnnot)["missing.e1", "labelDescription"] <-
  "fraction of genotype calls missing over all snps with missing.n1<1 except that Y chr SNPs are excluded for females"

# We can check summary statistics and make a histogram, too

summary(scanAnnot$missing.e1)
hist(
  scanAnnot$missing.e1,
  xlab = "Fraction of missing calls over all probes",
  main = "Histogram of Sample Missing Call Rate for All Samples"
)

```

Now, supply your code to calculate and store `missing.n2`. The steps you should follow are described in the comments below.

```{r missing.n2, eval=TRUE}

### Now that missing.n1 and missing.e1 have been calculated, we can calculate missing.n2

#   Recall that missing.n2 = missing call rate per SNP over all samples whose missing.e1
#   is less than 0.05.

#   Since no sample had missing.e1 > 0.05 in this dataset, we don't actually
#   have to exclude any samples.

#   However, let's proceed as if there were some samples with missing.e1 > 0.05.

#   Make a vector of the scanIDs for the samples with high missing.e1.

#   Apply the missingGenotypeBySnpSex function again, using the scan.exclude
#   argument.

#   Store missing.n2 as a new column in snpAnnot.

#   Update the metadata for snpAnnot!

#   The labelDescription for missing.n2 should be "fraction of genotype calls
#   missing over all samples with missing.e1 < 0.05 except that females are
#   excluded for Y chr SNPs"

#   <Your code goes here> ########################################

#   Make a vector of the scanIDs for the samples with high missing.e1.
snpexcl2 <- snpAnnot$snpID[snpAnnot$missing.e1 > 0.05]

#   Apply the missingGenotypeBySnpSex function again, using the scan.exclude
#   argument.
miss2 <- missingGenotypeBySnpSex(genoData, scan.exclude = snpexcl2) 

#   Store missing.n2 as a new column in snpAnnot.
snpAnnot$missing.n2 <- miss2$missing.fraction

#   Update the metadata for snpAnnot!
varMetadata(snpAnnot)["missing.n2", "labelDescription"] <-
  "fraction of genotype calls missing over all samples with missing.e1 < 0.05 except that females are excluded for Y chr SNPs"

# should make a histogram to see also
summary(snpAnnot$missing.n2)
hist(
  snpAnnot$missing.n2,
  xlab = "Fraction of call rate per SNP over all samples whose missing.e1 < 0.05",
  main = "Missing call rate per SNP over all samples whose missing.e1 < 0.05.",
  col = 'lightblue'
)
```

Write code to calculate and store `missing.e2`. The steps you should follow are described in the comments below.

```{r missing.e2, eval=TRUE}

### Last, we calculate missing.e2

#   Recall missing.e2 = missing call rate per sample over all SNPs with
#   missing.n2 values less than 0.05

#   Store a vector with the snpIDs of all probes with missing.n2 >= 0.05

#   Apply missingGenotypeByScanChrom to genoData again, using the snp.exclude
#   argument to exclude the SNPs with missing.n2 >= 0.05 (why do we do this?)

#   Make a new column in scanAnnot called missing.e2 to store the missingness
#   per-scan you just calculated

#   Update the scanAnnot metadata

#   The labelDescription should say "fraction of genotype calls missing over all
#   snps with missing.n2 < 0.05 except that Y chr SNPs are excluded for females"

#   <Your code goes here> ########################################

#   Store a vector with the snpIDs of all probes with missing.n2 >= 0.05
snpexcl3 <- scanAnnot$snpID[scanAnnot$missing.n2 >= 0.05]

#   Apply missingGenotypeByScanChrom to genoData again, using the snp.exclude
#   argument to exclude the SNPs with missing.n2 >= 0.05 (why do we do this?)
miss3 <- missingGenotypeByScanChrom(genoData, snp.exclude = snpexcl3) 

#   Make a new column in scanAnnot called missing.e2 to store the missingness
#   per-scan you just calculated
scanAnnot$missing.e2 <- miss$missing.fraction

#   Update the scanAnnot metadata
varMetadata(scanAnnot)["missing.e2", "labelDescription"] <-
  "fraction of genotype calls missing over all snps with missing.n2 < 0.05 except that Y chr SNPs are excluded for females"

# histogram 
summary(scanAnnot$missing.e2)
hist(
  scanAnnot$missing.e2,
  xlab = "Fraction of MCR per sample over all SNPs with missing.n2 values < 0.05",
  main = "Missing call rate per sample over all SNPs with missing.n2 < 0.05",
  col = 'mediumpurple'
)
```

## Part 1 - Report

Summarize the filtering you've accomplished at this step. Include the following in your answer the following questions.

-   (First, make sure you've filled in the calculations of `missing.n2` and `missing.e2` in the chunks above.)

-   How many SNPs and samples were genotyped?

-   Briefly describe the purpose of doing this step in two rounds (why do we calculate both missingnesses twice?)

-   What were the median, mean, and maximum per-sample missingness (use `missing.e2`)? Make a histogram of `missing.e2`.

-   How many samples had no missing calls at all (use `missing.e2`)?

-   Are the samples generally "good"? How many should be excluded from downstream analyses?

-   How many SNPs had a 100% missing call rate (use `missing.n1`)?

-   What are the median, mean, and maximum per-SNP missingnesses (use `missing.n2`)? How many SNPs are missing no calls at all?

-   Make a histogram of `missing.n2`.

-   How many SNPs are filtered out and how many remain if you retain only SNPs with `missing.n2` \< 0.05?

-   Make a histogram showing `missing.n2` for the remaining SNPs.

```{r part1_report}
library(ggplot2)

#   <Your code goes here>
sc <- pData(scanAnnot) # e1, e2
sn <- pData(snpAnnot) # n1, n2
head(sc) 
head(sn)

# How many SNPs and samples were genotyped?
sn %>%
  filter(missing.n1 != 1) %>%
  count() # 3149 

# missing.e2 histogram 
summary(scanAnnot$missing.e2)
hist(
  scanAnnot$missing.e2,
  xlab = "Fraction of MCR per sample over all SNPs with missing.n2 values < 0.05",
  main = "Missing call rate per sample over all SNPs with missing.n2 < 0.05",
  col = 'mediumpurple'
)

# How many samples had no missing calls at all (use missing.e2)?
sc %>%
  filter(missing.e2 == 0) # 1? this doesn't seem right but I can't figure out why?

# How many SNPs had a 100% missing call rate (use missing.n1)?
sn %>%
  filter(missing.n1 == 1) %>%
  count() # 151

# missing.n2 histogram
summary(snpAnnot$missing.n2)
hist(
  snpAnnot$missing.n2,
  xlab = "Fraction of call rate per SNP over all samples whose missing.e1 < 0.05",
  main = "Missing call rate per SNP over all samples whose missing.e1 < 0.05.",
  col = 'lightblue'
)

# What are the median, mean, and maximum per-SNP missingnesses (use missing.n2)? How many SNPs are missing no calls at all?
sn %>%
  filter(missing.n2 == 0) %>%
  count() # 2755

# How many SNPs are filtered out and how many remain if you retain only SNPs with missing.n2 < 0.05?
sn %>% 
  filter(missing.n2 < 0.05) %>%
  count() # 3095

# Make a histogram showing missing.n2 for the remaining SNPs.
hist(
sn$missing.n2[sn$missing.n2 < 0.05], # would be nice if base R cooperated with tidyverse
xlab = "Fraction of call rate per SNP after retaining SNPs with missing.n2 <0.05",
main = "Histogram of missing.n2 for remaining SNPs",
col = 'darkblue'
)
  
```

## Part 2 - Inferred vs. Reported Sex and Relatedness

To investigate discrepancies in inferred vs. reported sex (and, possibly, sex chromosome aneuploidies), we will produce four plots that summarize each scan's heterozygosity and intensity for the sex chromosomes:

1.  Mean Y chromosome vs. mean X chromosome intensity

2.  Mean X chromosome heterozygosity vs. mean X chromosome intensity

3.  Mean Y chromosome intensity vs. mean X chromosome heterozygosity

4.  Mean X chromosome heterozygosity vs. autosomal heterozygosity

Recall that the intensity data was read in earlier as `qxyData`. Before making our graphs, we'll need to calculate the variables we want to plot. The basic function we'll use to do this is `meanIntensityByScanChrom()`, which will return a list of matrices. Read the help file of this function so that you understand the output. Heterozygosity is calculated with `hetByScanChrom()`.

```{r sex_check, eval=TRUE}

#   Look at the structure of the IntensityData object

qxyData

#   For each probe, there's a numerical ID, chromosome, position, rsID

#   The intensities (stored as variables called X and Y) are each essentially
#   3300×77 matrices (an X and Y intensity for each scan for every single probe)

#   (Don't confuse the *intensity variable names* _X_ and _Y_ in the IntensityData
#   object with the X and Y *chromosomes*!)

#   Apply the meanIntensityByScanChrom function to get the intensity averages.
#   (We're not going to use all of the output from this function)

inten.by.chrom <- meanIntensityByScanChrom(qxyData)

#   Extract the matrix containing the mean intensity for each chromosome for
#   each scan

names(inten.by.chrom)
mninten <- inten.by.chrom$mean.intensity

#   The matrix is 77x6 since there are 77 samples and 6 chromosomes represented
#   in the dataset

dim(mninten)
head(mninten)

#   We also need to calculate the X chromosome and autosome heterozygosities for
#   each sample before we can plot them

#   Apply hetByScanChrom to genoData (we need actual genotypes to calculate the
#   heterozygosity)

het.results <- hetByScanChrom(genoData)

#   The function calculates eachs scan's heterozygosity for each chromosome, and
#   also for the autosomes as a whole

#   We want to add X and autosome heterozygosity as new columns in scanAnnot

#   Make sure the scanIDs are in the right order first! (they are)

allequal(scanAnnot$scanID, rownames(het.results))

#   Extract the autosomal and X heterozygosity and store them in scanAnnot

scanAnnot$het.A <- het.results[, "A"]
scanAnnot$het.X <- het.results[, "X"]

#   Add appropriate metadata

varMetadata(scanAnnot)["het.A", "labelDescription"] <-
  "fraction of heterozygotes for autosomal SNPs"
varMetadata(scanAnnot)["het.X", "labelDescription"] <-
  "fraction of heterozygotes for X chromosome SNPs"

#   Before making the plots, there are a few things to do

#   We want to color the plotted points by annotated sex

#   But first, make sure that the order of the scanIDs (and hence the annotated
#   sexes) matches the order of the scanIDs in the data we'll plot

allequal(scanAnnot$scanID, rownames(mninten))

#   Now we assign each sex a color (male=blue, female=red)

#   Store the colors in a vector

xcol <- rep(NA, nrow(scanAnnot))
xcol[scanAnnot$sex == "M"] <- "blue"
xcol[scanAnnot$sex == "F"] <- "red"

#   We also want to count the number of SNPs getting included on the X and Y
#   chromosomes (which are coded as 23 and 25 in snpAnnot)

nx <- sum(snpAnnot$chromosome == 23)
ny <- sum(snpAnnot$chromosome == 25)

# Now make the plots

# All intensities

x1 <- mninten[, "X"]
y1 <- mninten[, "Y"]
main1 <- "Mean X vs \nMean Y Chromosome Intensity"

# Het on X vs X intensity

x2 <- mninten[, "X"]
y2 <- scanAnnot$het.X
main2 <-
  "Mean X Chromosome Intensity vs Mean X Chromosome Heterozygosity"

# Het on X vs Y intensity

y3 <- mninten[, "Y"]
x3 <- scanAnnot$het.X
main3 <-
  "MeanX Chromosome Heterozygosity vs Mean Y Chromosome Intensity"

# X vs A het

x4 <- scanAnnot$het.A[scanAnnot$sex == "F"]
y4 <- scanAnnot$het.X[scanAnnot$sex == "F"]
main4 <-
  "Mean Autosomal Heterozygosity vs Mean X Chromosome Heterozygosity"

# Make labels for axes/legends

cols <- c("blue", "red")
mf <- c("male", "female")
xintenlab <- paste("X intensity (n=", nx, ")", sep = "")
yintenlab <- paste("Y intensity (n=", ny, ")", sep = "")

# Make the 4 plots and add a legend

par(mfrow = c(2, 2))
plot(
  x1,
  y1,
  xlab = xintenlab,
  ylab = yintenlab,
  main = main1,
  col = xcol,
  cex.main = 0.8
)
legend("bottomleft",
       mf,
       col = cols,
       pch = c(1, 1),
       cex = 0.5)
plot(
  x2,
  y2,
  col = xcol,
  xlab = xintenlab,
  ylab = "X heterozygosity",
  main = main2,
  cex.main = 0.8
)
plot(
  x3,
  y3,
  col = xcol,
  ylab = yintenlab,
  xlab = "X heterozygosity",
  main = main3,
  cex.main = 0.8
)
plot(
  x4,
  y4,
  col = "red",
  xlab = "Autosomal heterozygosity",
  ylab = "X heterozygosity",
  main = main4,
  cex.main = 0.8
)
par(mfrow = c(1, 1))

```

## Part 2 - Report (Sex Check)

-   Describe any anomalies you see in the 4 plots above.

-   Figure out the scanIDs of any scans that look like outliers or possible instances of mislabeled sex. Include these IDs in your report and describe why they appear to be mislabeled.

-   For the purposes of this assignment we will ASSUME that some scans have just had their sexes mislabeled. (In "real life", we would not just assume this, and we might instead flag these scans for removal from some downstream steps/analyses.)

-   Manually change the sex annotation for these scans in scanAnnot to "remove" the discrepancy. (Manually changing your data is risky and not generally recommended. Be careful!). In your report, state exactly what changes you made. Add a new column to scanAnnot indicating this, too (add appropriate metadata). Does anything in the pedigree structure make you more confident that this "fix" is correct? (Are these samples labeled as mothers or fathers?)

-   Remake the 4 plots above, using the "corrected" data (nothing should appear mislabeled now for this dataset).

-   How might you follow up on this "in real life"?

```{r part2_report_sex_check}

#   <Your code goes here>
sc <- pData(scanAnnot)

# Figure out the scanIDs of any scans that look like outliers or possible instances of mislabeled sex.
sc %>%
  filter(het.X < 0.1 & sex == 'F') # 0.1 is a bit of an arbitrary threshold, but I looked at the graphs and saw that there was a significant gap around this area

# Manually change the sex annotation for these scans in scanAnnot to "remove" the discrepancy. 
pData(scanAnnot)$sex[pData(scanAnnot)$sex == 'F' & pData(scanAnnot)$het.X < 0.1 ] <- 'M'
pData(scanAnnot) %>%
  filter(scanID == 325 | scanID == 326)
pData(scanAnnot) %>%
  filter(father == 200094287) # scanIDs listed above-- they're a father


# Remake the 4 plots above, using the "corrected" data (nothing should appear mislabeled now for this dataset).
#   Extract the matrix containing the mean intensity for each chromosome for
#   each scan
# names(inten.by.chrom)
# mninten <- inten.by.chrom$mean.intensity

#   Before making the plots, there are a few things to do

#   We want to color the plotted points by annotated sex
#   Now we assign each sex a color (male=blue, female=red)
#   Store the colors in a vector
xcol <- rep(NA, nrow(scanAnnot))
xcol[scanAnnot$sex == "M"] <- "blue"
xcol[scanAnnot$sex == "F"] <- "red"

#   We also want to count the number of SNPs getting included on the X and Y
#   chromosomes (which are coded as 23 and 25 in snpAnnot)
nx <- sum(snpAnnot$chromosome == 23)
ny <- sum(snpAnnot$chromosome == 25)

# Now make the plots

# All intensities
x1 <- mninten[, "X"]
y1 <- mninten[, "Y"]
main1 <- "Mean X vs \nMean Y Chromosome Intensity"

# Het on X vs X intensity
x2 <- mninten[, "X"]
y2 <- scanAnnot$het.X
main2 <-
  "Mean X Chromosome Intensity vs Mean X Chromosome Heterozygosity"

# Het on X vs Y intensity
y3 <- mninten[, "Y"]
x3 <- scanAnnot$het.X
main3 <-
  "MeanX Chromosome Heterozygosity vs Mean Y Chromosome Intensity"

# X vs A het
x4 <- scanAnnot$het.A[scanAnnot$sex == "F"]
y4 <- scanAnnot$het.X[scanAnnot$sex == "F"]
main4 <-
  "Mean Autosomal Heterozygosity vs Mean X Chromosome Heterozygosity"

# Make labels for axes/legends
cols <- c("blue", "red")
mf <- c("male", "female")
xintenlab <- paste("X intensity (n=", nx, ")", sep = "")
yintenlab <- paste("Y intensity (n=", ny, ")", sep = "")

# Make the 4 plots and add a legend
par(mfrow = c(2, 2))
plot(
  x1,
  y1,
  xlab = xintenlab,
  ylab = yintenlab,
  main = main1,
  col = xcol,
  cex.main = 0.8
)
legend("bottomleft",
       mf,
       col = cols,
       pch = c(1, 1),
       cex = 0.5)
plot(
  x2,
  y2,
  col = xcol,
  xlab = xintenlab,
  ylab = "X heterozygosity",
  main = main2,
  cex.main = 0.8
)
plot(
  x3,
  y3,
  col = xcol,
  ylab = yintenlab,
  xlab = "X heterozygosity",
  main = main3,
  cex.main = 0.8
)
plot(
  x4,
  y4,
  col = "red",
  xlab = "Autosomal heterozygosity",
  ylab = "X heterozygosity",
  main = main4,
  cex.main = 0.8
)
par(mfrow = c(1, 1))
```

## Part 3 - Allelic Imbalance; BAF and LRR Plots

Here we want to look at B allele frequency (BAF) and log R ratio (LRR) plots using `chromIntensityPlot()`. Ordinarily, since there are 22 to 23 chromosomes to check for every sample, you would use a script that automatically detects aberrations in BAF and LRR. For this project, we'll pretend that our pipeline has already flagged one sample for a possible chromosomal anomaly.

```{r baflrr, eval=TRUE}

# Recall that earlier we read the intensity data into an IntensityData object
# called blData.

# The snp/scan annotation were attached as well.

# Suppose that chromosome 22 was flagged for scanID 286.

# Making the BAF/LRR plot is easy

#dev.off()
chromIntensityPlot(blData, scan.ids = 286, chrom.ids = 22)
par(mfrow = c(1, 1))

```

## Part 3 - Report

-   Describe the purpose of this step.

-   Show an example of a "normal" pair of BAF/LRR plots (choose any chromosome/scanID you want).

-   How would you detect trisomy 21 (i.e., describe briefly in words what the BAF/LRR plot would look like).

-   Suppose an individual had a balanced reciprocal translocation involving chromosome 2 and 4. What would you expect that individual's BAF/LRR plots would look like for those chromosomes?

-   Suppose chromosome 22 in sample 286 was the only chromosome flagged for a possible anomaly in this dataset. Looking at the plot, do you notice anything strange? Can you suggest what kind of anomaly might be showing up? (There isn't any single answer that's certainly right! The purpose of this question is to check that you understand what the BAF and LRR plots "mean").

-   Finally, suppose your pipeline has given you a list of the exact chromosomal segments showing possibly aneuploidies/anomalies in each sample. What would you recommend doing with the genotypes in those segments? (You're not being asked to implement this here - just say what you recommend doing.)

```{r part3_report}
#  <Your code goes here>
# Show an example of a "normal" pair of BAF/LRR plots (choose any chromosome/scanID you want).
chromIntensityPlot(blData, scan.ids = 280, chrom.ids = 21)
par(mfrow = c(1, 1))
```

## Part 4 - Relatedness

Next, we estimate the identity-by-descent (IBD) coefficients for each pair of scans in order to describe genetic relatedness. There are various methods for doing this. We'll use the KING method, implemented in the `SNPRelate` package. The `pedigreeCheck` function will help us look for errors in the pedigree (i.e., the reported relationships) before comparing reported vs. genetic relatedness. Look at the help menu for this function to see what kinds of inconsistencies it reports on. Then `pedigreePairwiseRelatedness` will calculate the expected genetic relatedness for each pair of subjects, based on the reported pedigree structure.

```{r relatedness, eval=TRUE}

#   Close the connection to the genotypes gds file (recall that we changed the
#   sexes in the previous step, so we should "remake" genoData with the updated
#   annotation)
close(genoData)

#   Re-open the data
gds_geno <- system.file("extdata", "illumina_geno.gds", package="GWASdata")
gdsobj <- snpgdsOpen(gds_geno)

#   Let's use the snp.id argument to include only "good" SNPs in the calculation
#   (missing.n2 < 0.05)
snps_to_include_for_kinship <-
  snpAnnot$snpID[snpAnnot$missing.n1 < 0.05]

#   Apply snpgdsIBDKING to calculate relatedness statistics. The IBD object
#   returned is a list containing scanIDs, snpIDs, and two relatedness matrices
ibdobj <- snpgdsIBDKING(gdsobj, snp.id = snps_to_include_for_kinship)
snpgdsClose(gdsobj)
dim(ibdobj$kinship)

#   Observe that monomorphic and non-autosomal SNPs are also being excluded by
#   default

#   Recall that the relatedness matrices are symmetric 77×77 matrices (the entry
#   in row i, column j is the coefficient for samples i and j)
ibdobj$kinship[1:5, 1:5]

#   Next, we use pedigreeCheck to look for problems in the pedigree (duplicates,
#   impossible relationships, and other inconsistencies)

#   The goal is to clean up the pedigree before applying the functions that will
#   determine the expected relatedness coefficients

#   First, pull out all the pedigree information from the scan annotation (77
#   scans)
#   Notice that we're using subjectID and not scanID here (recall the
#   difference)
ped <-
  pData(scanAnnot)[, c("family", "subjectID", "father", "mother", "sex")]
dim(ped)

#   Rename the subjectID variable
names(ped) <- c("family", "individ", "father", "mother", "sex")
head(ped)

#   pedigreeCheck has returned a list of three data frames: duplicates,
#   parent.no.individ.entry, and unknown.parent.rows
chk <- pedigreeCheck(ped)
chk

#   We'll deal with these in turn

#   First, we remove duplicates from the pedigree

#   Get the data frame of duplicates from chk
dups <- chk$duplicates
head(dups)

#   Use the pedigreeDeleteDuplicates function to make a new pedigree with the duplicates removed
uni.ped <- pedigreeDeleteDuplicates(ped, dups)
dim(uni.ped)

#   Observe that uni.ped is smaller than ped

#   Now we apply pedigreeCheck again
chk <- pedigreeCheck(uni.ped)

#   Examining chk, we see that there are three types of problem

#   (Note that pedigreeCheck would have identified the mismatched sexes if we
#   had not fixed them already)

#   We deal with these in turn

#    parent.no.individ.entry
#    unknown.parent.rows
#    subfamilies.ident

chk

#   parent.no.individ.entry

#   This means the person in row 8 of uni.ped has a parent (mother) whose ID
#   (200039107) doesn't occur as an "individ" in the pedigree

#   We fix this by simply making and adding on a new row for this mother
ni <- chk$parent.no.individ.entry
ni
parent <-
  data.frame(
    family = ni$family,
    individ = ni$parentID,
    father = 0,
    mother = 0,
    sex = "F",
    stringsAsFactors = FALSE
  )

#   Call the new pedigree ped.updated and apply pedigreeCheck again
ped.updated <- rbind(uni.ped, parent)
chk <- pedigreeCheck(ped.updated)
chk

#   unknown.parent.rows

#   This means the person in row 42 of ped.updated has one parent known and one
#   missing

up <- chk$unknown.parent.rows
up

#   Let's look at this family (family 58)
ped.updated[ped.updated$family == 58, ]

#   Apparently the mother is unknown

#   Let's make up an individ ID for this mother, enter it it as the son's
#   mother's ID, and add a row to the pedigree for her
ped.updated[42, "mother"] <- 987654321
parent <-
  data.frame(
    family = up$family,
    individ = 987654321,
    father = 0,
    mother = 0,
    sex = "F",
    stringsAsFactors = FALSE
  )

#   Call the filled-out pedigree ped.complete, and apply pedigreeCheck
ped.complete <- rbind(ped.updated, parent)
chk <- pedigreeCheck(ped.complete)
chk

#   subfamilies.ident
subf <- chk$subfamilies.ident
subf
table(subf$family)

#   This identifies subfamilies (families where not everyone is linked into the
#   same pedigree as constructed by fathers'/mothers' IDs)

#   We should make these subfamilies into new families

#   Get the individuals from subfamily 2 from each family and add on "-2" their
#   family IDs
subf.ids <- subf$individ[subf$subfamily == 2]
newfam <- ped.complete$individ %in% subf.ids
ped.complete$family[newfam] <-
  paste0(ped.complete$family[newfam], "-2")

#   Now families 1341 and 1362 have been split into 2 trios (the new families
#   are 1341-2 and 1362-2)
table(ped.complete$family)

#   pedigreeCheck now returns NULL, meaning the pedigree now has no problems
pedigreeCheck(ped.complete)

#   Now we can calculate the pairwise expected relatedness for all the subjects
#   in the completed pedigree

#   The function pedigreePairwiseRelatedness returns a list summarizing the
#   relationships
rels <- pedigreePairwiseRelatedness(ped.complete)

#   First, we can see that none of the parents are related by looking at
#   inbred.fam
length(rels$inbred.fam)

#   Next we extract relativeprs, a data frame summarizing the relationships
relprs <- rels$relativeprs

#   It contains relationship type (e.g., parent-offspring, unrelated, etc.) and
#   kinship coefficient for each pair within each family
relprs[1:5,]
table(relprs$relation)

#   We see that our pedigree is relatively simple: 30 parent-offspring pairs
#   (PO) and 15 unrelated

#   (If we had a more complex pedigree structure, we would see more types of
#   relationships listed)

### Now we want to plot of the IBD coefficient estimates, color coded by the
### expected relationships we've just calculated

#   But first we need to merge together the expected and observed genetic
#   relationship data for all the pairs of scans

#   First, get all the scanIDs/subjectIDs from scanAnnot
samp <- pData(scanAnnot)[, c("scanID", "subjectID")]

#   Make sure the order matches that in the IBD object
samp <- samp[match(ibdobj$sample.id, samp$scanID), ]

#   Rename subjecID as Individ (like in the pedigree)
names(samp) <- c("scanID", "Individ")

#   Use snpgdsIBDSelection to find all pairs of samples with kinship coefficient
ibd <- snpgdsIBDSelection(ibdobj)

#   Merge in the subjectIDs that go with the scanIDs
ibd <- merge(ibd, samp, by.x = "ID1", by.y = "scanID")
ibd <-
  merge(
    ibd,
    samp,
    by.x = "ID2",
    by.y = "scanID",
    suffixes = c("1", "2")
  )

#   Create a pair-identifier variable to enable merging ibd with relprs (i.e.,
#   merge the observed and expected genetic relationship data)
ibd$ii <- pasteSorted(ibd$Individ1, ibd$Individ2)
relprs$ii <- pasteSorted(relprs$Individ1, relprs$Individ2)

#   Merge these together
ibd <- merge(ibd, relprs[, c("ii", "relation")], all.x = TRUE)

#   Rename the "relation" column (it refers to the expected relationship based
#   on the pedigree, so call it exp.rel)
names(ibd)[names(ibd) == "relation"] <- "exp.rel"

#   For pairs of samples from the same person, set exp.rel="Dup" (duplicate)
ibd$exp.rel[ibd$Individ1 == ibd$Individ2] <- "Dup"

#   For the remaining pairs with missing exp.rel, replace the missing value with "U" (unknown)
ibd$exp.rel[is.na(ibd$exp.rel)] <- "U"
table(ibd$exp.rel, useNA = "ifany")

#   Use the ibdAssignRelatednessKing function to call the observed relationships
#   based on IBS0 and kinship values for each pair
ibd$obs.rel <- ibdAssignRelatednessKing(ibd$IBS0, ibd$kinship)
table(ibd$obs.rel, useNA = "ifany")

# Finally, plot KC vs IBS0

# Draw horizontal thresholds for assigning relationships using kinship
# coefficients (taken from table 1 of Manichaikul (2010))
cut.dup <- 1 / (2 ^ (3 / 2))
cut.deg1 <- 1 / (2 ^ (5 / 2))
cut.deg2 <- 1 / (2 ^ (7 / 2))
cut.deg3 <- 1 / (2 ^ (9 / 2))
cols <- c(Dup = "magenta",
          PO = "cyan",
          U = "black")
plot(ibd$IBS0,
     ibd$kinship,
     col = cols[ibd$exp.rel],
     xlab = "Fraction of IBS=0",
     ylab = "Kinship coefficient")
abline(
  h = c(cut.deg1, cut.deg2, cut.deg3, cut.dup),
  lty = 2,
  col = "gray"
)
legend("topright",
       legend = names(cols),
       col = cols,
       pch = 1)

```

From the kinship plot, we see there are some inconsistencies between the expected and observed genetic relatedness statistics. Making a table of expected vs. observed relationships can summarize this. Taking "Deg3" and "U" ("Unrelated") as synonynmous here for simplicity, we would expect all the off-diagonal entries of the table below to be 0.

What we actually see is that 16 pairs that are supposedly unrelated are actually parent-offspring pairs; and 17 pairs that are supposedly parent-offspring pairs are showing up as genetically unrelated. Note that since there are multiple scans per person, there are a lot of relationships pairs here (77 scans implies 77 \* 76 / 2 = 2926 possible pairs, which is the sum of the entries in the table). Each of the 33 discrepancies is a 'dot' in the 'wrong cluster' in the IBD plot we drew.

Can we account for these discrepancies somehow? Let's try to find the pairs of individuals/families with discrepancies. We see below that only 3 families are involved (families 1344, 1334, and 58). After poring over the list of discrepancies, we also see that they can be disentangled somewhat. The discrepancy involving family 58 concerns only 2 scanIDs, 355 and 356 (both in the same family), so we can tackle it first. (On the other hand, the remaining 32 discrepancies involving families 1344 and 1334 seem more complex.) It appears the discrepancy is due to a case of non-paternity - the pedigree in scanAnnot says that 356 is 355's father, but the kinship calculation says they're genetically unrelated. Therefore we should change the family IDs to reflect that they're unrelated.

```{r relatedness2, eval=TRUE}

#   Make a table of obsereved and expected relationships for each pair of scans
ibd_recoded <- ibd
ibd_recoded$obs.rel[ibd_recoded$obs.rel == "Deg3"] <- "U"
table(expected = ibd_recoded$exp.rel, observed = ibd_recoded$obs.rel)

#   What are the pairs with discrepancies?

#   Print out all 33 rows
discrepancies <-
  ibd_recoded[!ibd_recoded$exp.rel == ibd_recoded$obs.rel, ]
discrepancies

#   Note that this table includes the scanIDs of each pair involved in a
#   discrepancy

### Which *families* are involved?

#   Get the individual scanIDs first and match them back to the family IDs
discrepancy_ids <- unlist(discrepancies[, c("ID1", "ID2")])
discrepany_fids <-
  pData(scanAnnot)$family[pData(scanAnnot)$scanID %in% discrepancy_ids]
discrepany_fids <- unique(discrepany_fids)
discrepany_fids

#   The discrepancy with individuals 355 and 356 from family 58 seems easiest to
#   fix first - it only involves one family
discrepancies[discrepancies$ID1  %in% c(355, 356) |
                discrepancies$ID2  %in% c(355, 356) ,]
pData(scanAnnot)[pData(scanAnnot)$family == "58", ]

#   Since 355 and 356 are actually unrelated, we should give one of them a new
#   family ID

#   Notice we use subjectID here

#   Set "daughter"'s father-ID to 0
pData(scanAnnot)[pData(scanAnnot)$subjectID == 200122151, "father"] <-
  "0"

#   Give the "dad" a new, unique family-ID
pData(scanAnnot)[pData(scanAnnot)$subjectID == 200105428, "family"] <-
  "58-2"
pData(scanAnnot)[pData(scanAnnot)$family == 58, ]
pData(scanAnnot)[pData(scanAnnot)$family == "58-2", ]

```

Now, you should account for the remaining discrepancies, which simply involve a sample swap between families 1334 and 1344. The sample swap involves just the children from two trios (each is scanned twice, and the parents are all scanned twice).

For the swapped samples, manually "fix" their family IDs, mother IDs, and father IDs in scanAnnot (i.e., swap these IDs back so that each child has the correct parental and family IDs). You only need to adjust the variables `family`, `father`, and `mother` for 4 scans from the 2 children. One of these has completed for you. **Add your code in the next chunk, where indicated.**

```{r relatedness3, eval=TRUE}

### Fixes

#   Print out the pedigree info before and after the "fix"

#   Need to update family, father, and mother for scanIDs 296, 297, 298, and 299

#   296 is done for you

#   Fill in the NAs with the correct values!

# pData(scanAnnot)[pData(scanAnnot)$family == 1334, ]
# pData(scanAnnot)[pData(scanAnnot)$family == 1344, ]

pData(scanAnnot) %>%
  filter(scanID >= 296 & scanID <= 299)

# Scan1 from Kid 1
pData(scanAnnot)[pData(scanAnnot)$scanID == 296, c("family", "father", "mother")] <-
  c(1334, 200118596, 200019634)

# Scan2 from Kid 1
pData(scanAnnot)[pData(scanAnnot)$scanID == 297, c("family", "father", "mother")] <-
  c(1334, 200118596, 200019634)

# Scan1 from Kid 2
pData(scanAnnot)[pData(scanAnnot)$scanID == 298, c("family", "father", "mother")] <-
  c(1344, 200116780, 200005043)

# Scan2 from Kid 2
pData(scanAnnot)[pData(scanAnnot)$scanID == 299, c("family", "father", "mother")] <-
  c(1344, 200116780, 200005043)

pData(scanAnnot) %>%
  filter(scanID >= 296 & scanID <= 299)

# pData(scanAnnot)[pData(scanAnnot)$family == 1334, ]
# pData(scanAnnot)[pData(scanAnnot)$family == 1344, ]

```

Now that we've "corrected" the sample-swaps, we should make a new IBD plot to verify that observed and expected relationships now match.

```{r relatedness4, eval=TRUE}

#   Recalculate the relatedness as above
# showfile.gds(closeall = TRUE) # close all files otherside gdsobj wouldn't run?
  # source https://github.com/zhengxwen/gdsfmt/issues/17#issuecomment-346899023 

gds_geno <-
  system.file("extdata", "illumina_geno.gds", package = "GWASdata")
snps_to_include_for_kinship <-
  snpAnnot$snpID[snpAnnot$missing.n1 < 0.05]
gdsobj <- snpgdsOpen(gds_geno) # this wouldn't run without closing everything first 
ibdobj <- snpgdsIBDKING(gdsobj, snp.id = snps_to_include_for_kinship)
snpgdsClose(gdsobj)

#   Re-draw the pedigree
ped <-
  pData(scanAnnot)[, c("family", "subjectID", "father", "mother", "sex")]
dim(ped)
names(ped) <- c("family", "individ", "father", "mother", "sex")
head(ped)
chk <- pedigreeCheck(ped)
chk

#   Remove duplicates, as before
dups <- chk$duplicates
head(dups)
uni.ped <- pedigreeDeleteDuplicates(ped, dups)
dim(uni.ped)
chk <- pedigreeCheck(uni.ped)
chk

#   Recall there was a person whose mother needed to be added to the pedigree

ni <- chk$parent.no.individ.entry
ni
parent <-
  data.frame(
    family = ni$family,
    individ = ni$parentID,
    father = 0,
    mother = 0,
    sex = "F",
    stringsAsFactors = FALSE
  )
ped.updated <- rbind(uni.ped, parent)
chk <- pedigreeCheck(ped.updated)
chk

#   Recall that a family had to be broken into two new sub-families

ped.complete <- ped.updated
chk <- pedigreeCheck(ped.complete)
subf <- chk$subfamilies.ident
subf
table(subf$family)
subf.ids <- subf$individ[subf$subfamily == 2]
newfam <- ped.complete$individ %in% subf.ids
ped.complete$family[newfam] <-
  paste0(ped.complete$family[newfam], "-2")
table(ped.complete$family)
pedigreeCheck(ped.complete)
chk <- pedigreeCheck(ped.complete)
chk

#   Earlier we split family 58 into two singleton families (the "father" and
#   "daughter" who weren't actually related) pedigreeCheck doesn't like
#   singletons, so we need to assign dummy parents for the original two members
#   of family 58 And these 4 dummy parents need to be added into the pedigree

onefams <- chk$one.person.fams
onefams
ped.complete[ped.complete$family %in% c("58", "58-2"), ]
ped.complete[ped.complete$family == "58",  c("father", "mother")] <-
  c("1111", "2222")
ped.complete[ped.complete$family == "58-2", c("father", "mother")] <-
  c("3333", "4444")

parents <- data.frame(
  family = c("58", "58", "58-2", "58-2"),
  individ = c("1111", "2222", "3333", "4444"),
  father = c(0, 0, 0, 0),
  mother = c(0, 0, 0, 0),
  sex = c("M", "F", "M", "F"),
  stringsAsFactors = FALSE
)

#   Complete the final pedigree, and now pedigreeCheck is happy (it returns NULL)

ped.final <- rbind(ped.complete, parents)
pedigreeCheck(ped.final)

# Recalculate expected relationships in order to make a new plot, as above

ped.complete <- ped.final
rels <- pedigreePairwiseRelatedness(ped.final)
length(rels$inbred.fam)
relprs <- rels$relativeprs
relprs[1:5, ]
table(relprs$relation)
samp <- pData(scanAnnot)[, c("scanID", "subjectID")]
samp <- samp[match(ibdobj$sample.id, samp$scanID), ]
names(samp) <- c("scanID", "Individ")
ibd <- snpgdsIBDSelection(ibdobj)
ibd <- merge(ibd, samp, by.x = "ID1", by.y = "scanID")
ibd <-
  merge(
    ibd,
    samp,
    by.x = "ID2",
    by.y = "scanID",
    suffixes = c("1", "2")
  )
ibd$ii <- pasteSorted(ibd$Individ1, ibd$Individ2)
relprs$ii <- pasteSorted(relprs$Individ1, relprs$Individ2)
ibd <- merge(ibd, relprs[, c("ii", "relation")], all.x = TRUE)
names(ibd)[names(ibd) == "relation"] <- "exp.rel"
ibd$exp.rel[ibd$Individ1 == ibd$Individ2] <- "Dup"
ibd$exp.rel[is.na(ibd$exp.rel)] <- "U"
table(ibd$exp.rel, useNA = "ifany")

#   Use the ibdAssignRelatednessKing function to call the observed relationships
#   based on IBS0 and kinship values for each pair

ibd$obs.rel <- ibdAssignRelatednessKing(ibd$IBS0, ibd$kinship)
table(ibd$obs.rel, useNA = "ifany")

#   Observe that now the observed and expected relationships match (if we take
#   Deg3 and Unrelated as synonymous)

table(ibd$exp.rel, ibd$obs.rel)

#   Finally, plot KC vs IBS0

#   Draw horizontal hresholds for assigning relationships using kinship
#   coefficients (taken from table 1 of Manichaikul (2010))

#   Now none of  the dots appear to be in the "wrong" clusters

cut.dup <- 1 / (2 ^ (3 / 2))
cut.deg1 <- 1 / (2 ^ (5 / 2))
cut.deg2 <- 1 / (2 ^ (7 / 2))
cut.deg3 <- 1 / (2 ^ (9 / 2))
cols <- c(Dup = "magenta",
          PO = "cyan",
          U = "black")
plot(ibd$IBS0,
     ibd$kinship,
     col = cols[ibd$exp.rel],
     xlab = "Fraction of IBS=0",
     ylab = "Kinship coefficient")
abline(
  h = c(cut.deg1, cut.deg2, cut.deg3, cut.dup),
  lty = 2,
  col = "gray"
)
legend("topright",
       legend = names(cols),
       col = cols,
       pch = 1)

```

## Part 4 - Report (Relatedness)

-   [Summarize the pedigree structures you observe in the data.]{.underline}

    -   There appears to be 34 duplicate pairs and 90 parent-offspring pairs, and most of the data (2802 points) is a large cluster of unrelated pairs.

-   [Describe what discrepancies you observe in the initial kinship vs IBS0 plot.]{.underline}

    -   Initially, there were several parent-offspring pairs located in the "unrelated" cluster and unrelated pairs located in the "parent-offspring" cluster.

-   [Explain exactly the kinds of swaps/discrepancies that were found, which IDs were involved, and exactly how you "fixed" them.]{.underline}

    -   It turns out there were four sample swaps (two subjects) for scanIDs 296 and 297 (from subjectID 200016815), 298 and 299 (from subjectID 200071490). This was corrected simply by manually swapping the mother, father, and family IDs from these two subjects.\
        There was also a discrepancy where the scanAnnot pedigree said that scanID 356 is 355's father, but according to the kinship calculation they are genetically unrelated. We corrected this by setting scanID 355's father to 0 and giving scanID 356 a new unique family ID (58_2 instead of 58).

-   [How would you recommend following up on these discrepancies "in real life" (instead of just assuming we know what happened and manually changing the data, which is a *bad idea*)?]{.underline}

    -   I would alert my PI of this first and see what they would like us to do. I would also ask the lab tech to see if it was an error on their end, and drop the sample if I was truly uncertain.

-   [Add a column to scanAnnot called "relationship.changes", which briefly summarizes these "fixes" (add metadata for the column, too).]{.underline}

```{r part3_report_relatedness}

#   <Your code goes here>
# Summarize the pedigree structures you observe in the data.
table(ibd$exp.rel)

# Add a column to scanAnnot called "relationship.changes", which briefly summarizes these "fixes" (add metadata for the column, too).
scanAnnot$relationship.changes <- NA
  # if scanID = 296, 297, 298, 299, 356, 355, value is something else 

s <- pData(scanAnnot) 
s$relationship.changes <- NA
s <- s %>%
    mutate(relationship.changes = case_when(
      scanID >= 296 & scanID <= 299 ~ "sample_swap",
      scanID == 356 | scanID == 355 ~ "unrelated",
    ))
head(s)
# turn this back into a SnpAnnotationDataFrame called scanAnnot
scanAnnot <- ScanAnnotationDataFrame(s)

varMetadata(scanAnnot)["relationship.changes", "labelDescription"] <- "relationship fixes"

pData(scanAnnot) %>%
  filter(scanID >= 296 & scanID <= 299)
pData(scanAnnot) %>%
  filter(scanID >= 355 & scanID <= 356)

head(pData(scanAnnot))
varMetadata(scanAnnot)
```

## Part 5 - Principal component analysis (PCA) and population substructure

Here you'll be introduced to performing PCA to uncover population substructure.

```{r pca, eval=TRUE}

#   For input when we calculate PCA, we want to exclude SNPs from a few
#   problematic loci

#   Including SNPs from 2q21 (LCT), HLA, 8p23, and 17q21.31 can result PCs that
#   are highly correlated with these SNPs, which is undesirable

#   GWASTools supplies the positions of these loci in the relevant genome build
#   in a data frame called pcaSnpFilters.hg18

#   (Note that these loci are on chromosomes 2, 6, 8, and 17, which aren't
#   included in our genotyping data; we'll proceed in this example as if we had
#   genome-wide SNPs)
filt <- get(data(pcaSnpFilters.hg18))

#   Next we pull out the chromosomes, positions, and IDs of the SNPs in our
#   dataset
chrom <- getChromosome(snpAnnot)
pos <- getPosition(snpAnnot)
snpID <- getSnpID(snpAnnot)
snp.filt <- rep(TRUE, length(snpID))

#   We loop over the 4 regions to be excluded and identify which of our SNPs lie
#   with the endpoints of each
for (f in 1:nrow(filt)) {
  snp.filt[chrom == filt$chrom[f] &
             filt$start.base[f] < pos & pos < filt$end.base[f]] <- FALSE
}

#   Make a vector called snp.sel containing the snpIDs of SNPs not in the
#   problematic regions; these are the SNPs we'll retain for PCA
snp.sel <- snpID[snp.filt]
length(snp.sel)

#   (None of our 3300 SNPs get filtered out in this step, since they're not on
#   chromosomes 2, 6, 8, or 17)


### We also want to filter out some samples before running PCA

### Specifically, we shouldn't include duplicates (for subjects with multiple
### samples, we'll just pick one sample)

#   We'll re-order scanAnnot by missing.e1 so duplicate subjectIDs with a higher
#   missing rate are marked as duplicates

#   It's important that scanAnnot stays in the same order when we're done

#   Before changing the order, verify that scanAnnot is ordered by increasing
#   scanID (it is)
allequal(scanAnnot$scanID, sort(scanAnnot$scanID))

#   Now re-order so that duplicate subjectIDs with a higher missing rate are
#   marked as duplicates
scanAnnot <-
  scanAnnot[order(scanAnnot$subjectID, scanAnnot$missing.e1), ]

#   Add a new column called "duplicated" indicating who the duplicates are
scanAnnot$duplicated <- duplicated(scanAnnot$subjectID)
table(scanAnnot$duplicated, useNA = "ifany")

#   Put scanAnnot back in scanID order; this is very important!
scanAnnot <- scanAnnot[order(scanAnnot$scanID), ]
allequal(scanAnnot$scanID, sort(scanAnnot$scanID))

#   Update the metadata
varMetadata(scanAnnot)["duplicated", "labelDescription"] <-
  "TRUE for duplicate scan with higher missing.e1"

#   Now make a vector of the scanIDs, leaving out the duplicates with higher
#   missingness (43 remain)
sample.sel <- scanAnnot$scanID[!scanAnnot$duplicated]
length(sample.sel)

#   Note that in some applications you would only want to include unrelated
#   subjects when calculating PCs

#   In this exploratory example, we'll include parents and their children
#   instead of restricting ourselves to unrelated "founders""


### Now we can perform LD pruning, where independent SNPs are chosen using a
### "sliding window" along the chromosomes

### Re-open the genotypes (after making sure the previous connection is closed)

#close(genoData)
showfile.gds(closeall = T)
gdsobj <- snpgdsOpen(genofile)

### Use the snpgdsLDpruning function

#   · sample.id/snp.id are used to retain only the samples/SNPs we picked out
#     above
#   · only autosomal SNPs are used
#   · a MAF threshold of 5% is applied
#   · the maximum window size we use is 1 megabase
#   · the LD threshold is set

#   Read the Details section of the help page for snpgdsLDpruning to understand
#   how the pruning algorithm work
snpset <- snpgdsLDpruning(
  gdsobj,
  sample.id = sample.sel,
  snp.id = snp.sel,
  autosome.only = TRUE,
  maf = 0.05,
  missing.rate = 0.05,
  method = "corr",
  slide.max.bp = 10e6,
  ld.threshold = sqrt(0.1)
)
snp.pruned <- unlist(snpset, use.names = FALSE)
length(snp.pruned)

#   The output is a list the SNPs on each chromosome

#   (Roughly 180 SNPs are retained. Note that this procedure includes a random
#   process, so the number of SNPs selected will vary)


#   Now we calculate the PCs by applying snpgdsPCA, using only the pruned SNPs
#   and the samples selected earlier
pca <- snpgdsPCA(gdsobj, sample.id = sample.sel, snp.id = snp.pruned)
dim(pca$eigenvect)
head(pca$eigenvect)

#   The function returns a list of 8 objects, including the eigenvectors and the
#   ordered scanIDs

#   32 eigenvectors/PCs have been provided (in order); they're stored in
#   pca$eigenvect, a 43x32 matrix (43 samples by 32 eigenvectors)

```

## Part 5 - Report

-   [How many SNPs were used to calculate PCs?]{.underline}

    -   166 SNPs.

-   [Make pairwise scatterplots of the first 4 PCs, using different plotting symbols for the two populations, as reported in the "race" variable in scanAnnot.]{.underline}

-   [Make a parallel coordinate plot for the first 4 plots as well, again distinguishing the plotted lines according to the "race" variable.]{.underline}

-   [What information does the first PC appear to convey?]{.underline}

    -   The first PC shows the axis of greatest variance which in this case, is the population stratification.

```{r part4_report}
library(GGally) # thank you Caylin Grove for this suggestion! 
# https://r-charts.com/correlation/ggpairs/ 

scan <- pData(scanAnnot)
head(scan)

# Make pairwise scatterplots of the first 4 PCs, using different plotting symbols for the two populations, as reported in the "race" variable in scanAnnot.
# turn eigenvectors into dataframe
pcs <- data.frame(pca$eigenvect) # thank you again Caylin Grove 
head(pcs)

# turn sample.ids into dataframe
samples <- data.frame(pca$sample.id)
head(samples)

# add race column to sample.id dataframe
join <- samples %>%
  left_join(select(scan, scanID, race), join_by(pca.sample.id == scanID))
head(join)
dim(join)
dim(pcs)

# merge race + samples with PCs (43 rows each)
pcs2 <- cbind(join, pcs)
head(pcs2)

ggpairs(pcs2,
        columns = 3:6,
        aes(color = race, alpha = 0.2)) 

# Make a parallel coordinate plot for the first 4 plots as well, again distinguishing the plotted lines according to the "race" variable.
ggparcoord(pcs2,
           columns = 3:6, groupColumn = 2)

```

## Part 6 - Duplicate Sample Discordance

Here we leverage the duplicate samples to assess genotyping errors. If the same probe often yields different genotypes for duplicate scans from the same subjects, we should probably exclude the genotypes called from that probe. We will use the function `duplicateDiscordance`.

```{r discordance, eval=TRUE}

#   First, we should only use high-quality scans to when we judge the probes
scan.excl <- scanAnnot$scanID[scanAnnot$missing.e1 >= 0.05]
length(scan.excl)

#   (Recall that none of our scans had high missingness, so we don't have to
#   exclude anyone in this dataset)

#   We also don't want to bother testing for discordance in SNPs that are 100%
#   missing, so we exclude those, too
snp.excl <- snpAnnot$snpID[snpAnnot$missing.n1 == 1]
length(snp.excl)

#   Get the genotype data (make sure the connection to the file is closed before
#   reopening it)

#close(genoData)
showfile.gds(closeall = T, verbose = T)
genofile <-
  system.file("extdata", "illumina_geno.gds", package = "GWASdata")
genoGDS <- GdsGenotypeReader(genofile)

#   Attach the annotation to it (note that the sex/relatedness information were
#   "fixed" above)
genoData <-
  GenotypeData(genoGDS, snpAnnot = snpAnnot, scanAnnot = scanAnnot)

#   Now we use the dupdisc function to calculate the discordance for each SNP
#   (while excluding any low-quality scans and 100%-missing SNPs)
dupdisc <-
  duplicateDiscordance(
    genoData,
    subjName.col = "subjectID",
    scan.exclude = scan.excl,
    snp.exclude = snp.excl
  )

#   The function returns a list of 3 objects: discordance.by.snp,
#   discordance.by.subject, and correlation.by.subject
names(dupdisc)
dim(dupdisc$discordance.by.snp)
head(dupdisc$discordance.by.snp)

#   discordance.by.snp has a row for each SNP, detailing the number of
#   duplicate-pairs of scans observed for that SNP, the number of discordant
#   gentoypes observed among those pairs, and the discordance rate
length(dupdisc$discordance.by.subject)

#   discordance.by.subject is a list of matrices. For each subject with
#   duplicate scans, the matrix shows the discordance between the pairs of scans
#   (i.e., at what proportion of SNPs do two scans from the same person have
#   different genotypes?)
dupdisc$discordance.by.subject[[1]]

#   For the first subject in dupdisc$discordance.by.subject (scans 280/281), it
#   looks like the genotypes agreed for all the SNPs
dupdisc$discordance.by.subject[[2]]

#   For the second subject (scans 282/283), the discordance rate was
#   0.0003265839

#   Save a summary of this information by merging the discordances into the SNP
#   annotation

snpAnnot$dummy <- 1:nrow(pData(snpAnnot))
pData(snpAnnot) <-
  merge(
    x = pData(snpAnnot),
    y = dupdisc$discordance.by.snp[, c("snpID", "discordant")],
    all.x = T,
    all.y = F
  )

#   Make sure the order of the SNPs is maintained

pData(snpAnnot) <- pData(snpAnnot)[order(snpAnnot$dummy), ]
```

## Part 6 - Report

Briefly explain the purpose of this step and what it means to check for discordant genotypes. Summarize the results. Be sure to answer the following:

-   [How many SNPs are discordant in at least one duplicate-pair?]{.underline}

    -   25 SNPs are discordant in at least one duplicate-pair.

-   [What's the maximum number of discordances seen for any SNP?]{.underline}

    -   2 discordances.

-   [What's the median discordance rate? What's the maximum discordance rate?]{.underline}

    -   Median discordance rate: 0

    -   Maximum discordance rate: 0.0740741

-   [Decide and explicitly state the threshold, n, for filtering out SNPs based on discordance (i.e., SNPs with dupdisc\$discordance.by.snp \>= n will be removed)]{.underline}

    -   At an npair value of 34, SNPs with a discordance \>= 1 should be removed.

        -   (As stated in Geno_QC_Mendelian_Errors slide 17)

-   [You may find it helpful to call the function duplicateDiscordanceProbability(npair=34). Read the documentation for this function.]{.underline}

-   [Of the SNPs pass that passed the missing.n2 filter (missing.n2 \< 0.05), how many SNPs pass/fail the discordance threshold?]{.underline}

    -   All 3074 SNPs that passed missing.n2 \< 0.05 also pass the discordance threshold \< 1.

-   [Of the SNPs with missing.n2 \< 0.05, make a histogram of the discordance rate]{.underline}

    -   See coding block below.

-   [Make sure you add a new column to snpAnnot called failed.dup.disc ("pass" if the SNP had \>=n discordant calls, "fail" if it failed, "untested" if it was one of the high-missingness SNPs that we excluded); update the metadata]{.underline}

    -   See coding block below.

```{r part5_report}

#   <Your code goes here>

# How many SNPs are discordant in at least one duplicate-pair?
d <- data.frame(dupdisc$discordance.by.snp)
d %>%
  filter(discordant > 0) %>%
  count()

# What's the maximum number of discordances seen for any SNP?
d[which.max(d$discordant),]

# What's the median discordance rate? What's the maximum discordance rate?
summary(d$discord.rate)

# Decide and explicitly state the threshold, n, for filtering out SNPs based on discordance (i.e., SNPs with dupdisc$discordance.by.snp >= n will be removed)
plot(d$discord.rate)

# You may find it helpful to call the function duplicateDiscordanceProbability(npair=34). Read the documentation for this function.
disc <- duplicateDiscordanceProbability(npair=34)
#probability of observing >0 discordant genotypes given number of pairs = 34 
disc[1,1]
#probability of observing >1 discordant genotypes given number of pairs = 34 
disc[2,2] 

# Of the SNPs pass that passed the missing.n2 filter (missing.n2 < 0.05), how many SNPs pass/fail the discordance threshold?
pData(snpAnnot) %>%
  filter(missing.n2 < 0.05) %>%
  filter(discordant < 1) %>%
  count() # all 3074 SNPs pass

# Of the SNPs with missing.n2 < 0.05, make a histogram of the discordance rate
sn <- pData(snpAnnot)

# merge missing.n2 to the d dataframe, on snpID -- then filter by missing.n2 < 0.05
d2 <- d %>%
  left_join(select(sn, snpID, missing.n2), join_by(snpID)) %>% 
  filter(missing.n2 < 0.05)

hist(d2$discord.rate,
xlab = "Discordance rate after retaining SNPs with missing.n2 <0.05",
main = "Histogram of discordance rate of the SNPs with missing.n2 < 0.05",
col = 'darkblue'
)

# Make sure you add a new column to snpAnnot called failed.dup.disc ("pass" if the SNP had >=n discordant calls, "fail" if it failed, "untested" if it was one of the high-missingness SNPs that we excluded); update the metadata
snpAnnot$failed.dup.disc <- NA
pData(snpAnnot) <- pData(snpAnnot) %>%
  mutate(failed.dup.disc = case_when(
      discordant < 1 ~ "pass",
      discordant > 1 ~ "fail",
      missing.n2 < 0.05 ~ "untested"
      ))

head(sn)
varMetadata(snpAnnot)["failed.dup.disc", "labelDescription"] <-
  paste(
    "pass if the SNP had >=n discordant calls, fail if it failed, untested if it was one of the high-missingness SNPs that we excluded"
  )
varMetadata(snpAnnot)
```

## Part 7 - Hardy-Weinberg Equilibrium (HWE) testing

Deviations from HWE can indicate poor genotyping. Here you will appropriately test for departures from HWE in the data using `exactHWE` (which applies Fisher's exact test).

```{r hwe, eval=TRUE}

#   The test we'll use for HWE will assume independent observations

#   Therefore we should include only one scan from each subject

#   We should also include only "founders" (for this example, that means
#   excluding the children, whose genotypes aren't independent of their
#   parents')

#   The nonfounders are the individuals who have a mother or father in the
#   pedigree

head(pData(scanAnnot)[, c("father", "mother")])
nonfounders <- scanAnnot$father != 0 & scanAnnot$mother != 0
table(nonfounders)

#   HWE is sensitive to population stratification (A SNP can be in HWE in each
#   of two populations, but out of HWE in the combined population)

#   Therefore in this example we'll focus on HWE in just one population group,
#   the "CEU" group

#   So we'll exclude populations other than CEU, nonfounders, and duplicates
#   (recall tha that the "duplicated" variable was defined to include the scan
#   with better missingness for each subject)

scan.excl <-
  scanAnnot$scanID[scanAnnot$race != "CEU" |
                     nonfounders | scanAnnot$duplicated]
length(scan.excl)

#   Now we use exactHWE to calculate HWE statistics

#   We do this separately for the sex chromosomes

chr <- getChromosome(genoData)
auto <- range(which(chr %in% 1:22))
X <- range(which(chr == 23))

#   exactHWE takes snpStart/snpEnd arguments; we use these to identify the
#   indices corresponding to autosomal/sex chromosome SNPs

hwe <-
  exactHWE(
    genoData,
    scan.exclude = scan.excl,
    snpStart = auto[1],
    snpEnd = auto[2]
  )
hweX <-
  exactHWE(
    genoData,
    scan.exclude = scan.excl,
    snpStart = X[1],
    snpEnd = X[2]
  )

#   We use the scan.exclude argument to exclude non-CEU, non-founders, and duplicates

#   exactHWE has returned a data frame of HWE statistics for each SNP; read the help page to see what the columns are

#   Attach the two data frames

hwe <- rbind(hwe, hweX)
names(hwe)
#close(genoData)

#   Check on sample sizes for autosomes

hwe$N <- hwe$nAA + hwe$nAB + hwe$nBB
summary(hwe$N[is.element(hwe$chr, 1:22)])

#   ... and for the X chromosome

summary(hwe$N[is.element(hwe$chr, 23)])

#   Notice there are some missing p-values for the autosomes

#   ... and for X

#   We can view some of the genotype counts

#   The first SNP appears to be 100% missing, and the second is monomorphic
#   (i.e., MAF=0)

#   (recall that we didn't filter out SNPs here)

hwe$pval[1:10]
sum(is.na(hwe$pval[hwe$chr == 23]))
head(hwe[, c("nAA", "nAB", "nBB")])

#   Now we want to inspect deviation from HWE

#   We can use Q-Q plots to help with this

#   We should exclude monomorphic SNPs

hwe.0 <- hwe[hwe$MAF > 0, ]
dim(hwe.0)

#   Only keep the autosomal SNPs for first plot

pval <- hwe.0$pval[is.element(hwe.0$chr, 1:22)]
length(pval)

#   Double-check that there are no missing p-values remaining

pval <- pval[!is.na(pval)]
length(pval)

#   Similarly, get the p-values for the X-chromosome

pval.x <- hwe.0$pval[is.element(hwe.0$chr, 23)]
length(pval.x)
pval.x <- pval.x[!is.na(pval.x)]
length(pval.x)

#   Now make Q-Q plots

par(mfrow = c(2, 2))
qqPlot(pval = pval,
       truncate = FALSE,
       main = "Autosomes, all")
qqPlot(pval = pval,
       truncate = TRUE,
       main = "Autosomes, truncated")
qqPlot(pval = pval.x,
       truncate = FALSE,
       main = "X chromosome, all")
qqPlot(pval = pval.x,
       truncate = TRUE,
       main = "X chromosome, truncated")
par(mfrow = c(1, 1))

```

## Part 7 - Report

Briefly explain the purpose of HWE testing. In describing your results for this step, answer the folowing:

-   [How do you choose what subjects to include for HWE testing? How many were used here?]{.underline}

    -   Since HWE is sensitive to population substructure, we stratified by ancestry and chose only subjects from one race group (here, we picked CEU). We also only want to include "founders" or individuals who do not have parents in the pedigree, and we want to remove duplicates as well. After this filtering, we are left with 3000 SNPs.

-   [Interpret the Q-Q plots. Do any SNPs appear to be strongly out of HWE? Which SNPs? What are the lowest p-values?]{.underline}

    -   The Q-Q plots are not horrible, though not excellent, but the X chromosome graph in particular is not very good as it exhibits a stepped distribution and does not align well with the reference line. The SNPs on the X chromosome seem most strongly out of HWE. The lowest p-value is p = 5.616715e-05.

-   [For the autosomal SNPs, make a plot of -log10(p-value) vs MAF. Make another such plot for the X chromosome.]{.underline}

-   [What p-value will you use for filtering our SNPs with low HWE? Of the SNPs with missing.n2 \< 0.05, how many will be retained/removed?]{.underline}

    -   I chose p = 0.75 from looking at the scatterplots– there seems to be a large gap between values greater than and less than 0.75. Using this threshold, 2353 SNPs are filtered out, leaving the data with 947 SNPs (from the original 3300).

-   [Add the HWE p-values to the SNP annotation (and update the metadata)]{.underline}

```{r part6_report}
#   <Your code goes here>
# What are the lowest p-values?
hwe[which.min(hwe$pval),] # 5.616715e-05	

head(hwe)

# For the autosomal SNPs, make a plot of -log10(p-value) vs MAF. Make another such plot for the X chromosome.
hwe %>% # autosomal
  filter(chr >= 1 | chr <= 22) %>%
  ggplot() +
  geom_point(aes(x = MAF, y = pval), col = 'salmon') + 
  labs(title = '-log10(p-value) vs MAF in autosomal SNPs')

hwe %>% # X chr
  filter(chr == 23) %>%
  ggplot() +
  geom_point(aes(x = MAF, y = pval), col = 'turquoise') + 
  labs(title = '-log10(p-value) vs MAF in X chromosome')


# Add the HWE p-values to the SNP annotation (and update the metadata)
d2 <- d %>%
  left_join(select(sn, snpID, missing.n2), join_by(snpID)) %>% 
  filter(missing.n2 < 0.05)

p <- pData(snpAnnot) %>%
  left_join(select(hwe, snpID, pval), join_by(snpID))
# turn this back into a SnpAnnotationDataFrame called snpAnnot
snpAnnot <- SnpAnnotationDataFrame(p)
varMetadata(snpAnnot)["pval", "labelDescription"] <-
  paste(
    "Hardy-Weinberg Equilibrium p-values"
  )
head(pData(snpAnnot))

# What p-value will you use for filtering our SNPs with low HWE? Of the SNPs with missing.n2 < 0.05, how many will be retained/removed?
p %>%
  filter(missing.n2 < 0.05) %>%
  filter(pval <= 0.75) %>% # from our scatterplots
  count() # 947

p %>% # all
  ggplot() +
  geom_point(aes(x = missing.n2, y = pval), col = 'blue') +
  labs(title = '-log10(p-value) vs MAF in all SNPs')
```

**NOTE: I, Caylin Grove, and Ceceilagh Pitstick reviewed our code with each other after we finished the assignment.**
